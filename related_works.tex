\section{Related Works}
\label{Sec:RelatedWorks}

%I/O contention in HPC systems draws a lot of attention in the community,
%because it is one of the major culprits for parallel applications and performance variability.
%Hashimoto et al. evaluate the performance variability of each job
%when the jobs run concurrently on the same physical computing server.
%They identify that the network I/O sharing contributes the most to
%the performance degradation \cite{hashimoto:ICNC:2012}.
%Dorier et al. analyze the I/O interference between two applications.
%They make quantified study about the performance improvement obtained
%by interrupting or delaying one application in order to avoid I/O contention \cite{dorier:IPDPS:2014}.
%Yildiz et al. \cite{yildiz:IPDPS:2016} explore the variou root causes
%of I/O interference in HPC storage systems.
%They find that in many situations, interference is the result of the bad flow control in the I/O path,
%but is not caused by a single bottleneck in one of its components.

%The solutions to alleviate I/O contention between concurrently
%running jobs have been proposed in several recent works.
%Lofstead et al. propose to individually schedule each application's I/O requests without
%a global view from the system's perspective \cite{lofstead:sc:2010}.
%Their solutions require the support from the specific I/O management
%in the system level to achieve good results.
%Zhou et al. design a new I/O aware batch scheduler to address the I/O
%contention problem at the batch scheduling level \cite{zhou:Cluster:2015}.
%The new scheduler coordinates the  I/O requests without hurting the fairness across applications.
%Liu et al. propose to move many file handling procedures to the I/O nodes to
%ameliorate the I/O pressure from the massive number of compute nodes\cite{Liu:MSST:2012}.

%SLURM develops a new module for its batch scheduler that allocates burst buffer
%resources to the submitted user jobs. With the pre-allocated burst buffer,
%the I/O performance of user jobs is greatly improved \cite{SlurmBBGuide}.
%However, the policy they used for the resource allocation is in a first-come, first-serve manner without optimization.
%PBS supports burst buffer aware scheduling in similar way as SLURM, 
%jobs are only dispatched when required burst buffer resource are ready\cite{PBSonCRAY}. 
%Their static burst buffer aware scheduling strategies would lead to low resource utilization.

%Our work is different from the existing research in the following ways.
%We target intelligently assigning burst buffer as a new system resource to the submitted user jobs.
%In our scheduling model, users are encouraged to provide the burst buffer demand when submitting the jobs.
%Based on the possible usage cases of burst buffer, the execution of user jobs is modeled into three phases.
%The user jobs request different resources in each phase.
%We propose a new batch scheduler with burst buffer awareness, Cerberus,
%making scheduling decisions for jobs in each specific phase.
%We also integrate Cerberus with different optimization algorithms for the
%objectives of maximizing the resource utilization and the system throughput.

